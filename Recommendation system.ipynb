{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "header = ['user_id','item_id','rating','timestamp']\n",
    "df = pd.read_csv('/Users/psrini1/Documents/Python/Recommendation system/ml-100k/u.data', sep ='\\t', names = header)\n",
    "## Extracting specific columns from the dataframe\n",
    "select = [\"user_id\",\"item_id\"]\n",
    "df[select]\n",
    "\n",
    "## Getting the unique count of users / items \n",
    "\n",
    "users = df.user_id.unique().shape[0]\n",
    "users ## 943unique users\n",
    "items = df.item_id.unique().shape[0]\n",
    "items ## 1682 unique movies\n",
    "\n",
    "## Splitting the data using CV \n",
    "from sklearn import cross_validation as cv\n",
    "train_data,test_data = cv.train_test_split(df,test_size = 0.25)\n",
    "\n",
    "## Creating the user-item matrix \n",
    "train_data_matrix = np.zeros((users,items))\n",
    "train_data_matrix\n",
    "\n",
    "test_data_matrix = np.zeros((users,items))\n",
    "\n",
    "## Check what's stored in line\n",
    "##for line in train_data.itertuples():\n",
    "  ##  print(line)\n",
    "\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix [line[1]-1,line[2]-1]= line[3]\n",
    "\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1,line[2]-1] =line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculating item and user based similarity scores \n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances  \n",
    "\n",
    "user_similarity = pairwise_distances(train_data_matrix,metric ='cosine')\n",
    "\n",
    "item_similarity = pairwise_distances(train_data_matrix.T,metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1454.2260641 ,  1479.78585468,  1525.07625219, ...,  1669.43636309,\n",
       "        1652.27459153,  1655.3895763 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.abs(item_similarity).sum(axis=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ndarray(shape=(2,2),dtype = int, order = 'F')\n",
    "b = np.abs(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## User-user CF\n",
    "\n",
    "## Averge rating for each user\n",
    "def prediction(rating,similarity,type):\n",
    "    if type == 'user':\n",
    "        mean_rating = rating.mean(axis=1)\n",
    "        rating_diff = rating-mean_rating[:,np.newaxis]\n",
    "        pred = mean_rating[:,np.newaxis] + similarity.dot(rating_diff)/ np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = rating.dot(similarity)/np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_prediction = prediction(train_data_matrix,item_similarity,type = 'item')\n",
    "user_prediction = prediction(train_data_matrix,user_similarity,type ='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = test_data[\"user_id\"] == 1\n",
    "c2 = test_data[\"item_id\"] == 1\n",
    "\n",
    "##train_data[train_data[\"user_id\"] == 38 & train_data[\"item_id\"] == 758]\n",
    "test_data[c1 & c2]\n",
    "test_data_matrix[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1253595439463076"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Evaluation of the model predictions \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def rmse_eval(actual,prediction):\n",
    "    prediction = prediction[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(actual,prediction))\n",
    "\n",
    "rmse_eval(test_data_matrix,user_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 943 is out of bounds for axis 0 with size 943",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e3b0678e3faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrmse_eval1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-e3b0678e3faf>\u001b[0m in \u001b[0;36mrmse_eval1\u001b[0;34m(actual, prediction)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrmse_eval1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 943 is out of bounds for axis 0 with size 943"
     ]
    }
   ],
   "source": [
    "def rmse_eval1(actual,prediction):\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    prediction = prediction[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction,actual))\n",
    "\n",
    "rmse_eval1(test_data_matrix,user_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  3.,  5., ...,  5.,  3.,  3.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_matrix[test_data_matrix.nonzero()].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.6352657 ,  0.56878181,  0.37196922, ...,  0.29504158,\n",
       "        0.17447012,  0.16571898])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction[test_data_matrix.nonzero()].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
